{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Integration\n",
    "\n",
    "## PHYS 212\n",
    "## Dr. Wolf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Two Main Types of Numerical Integration: Definite Integrals\n",
    "Within this type of integration, there are two **more** scenarios to consider\n",
    "### Analytic Function, but Impossible to Find an Antiderivative, or \"Black Box\" Function\n",
    "Function that cannot be easily anti-differentiated, like\n",
    "$$ \\int_{0}^3 e^{-x}\\sin(x^2)\\,dx $$\n",
    "\n",
    "Or, function is a \"black box\" (maybe its the output of some other program), and we thus cannot find an anti-derivative, but we *can* generate an arbitrary number of $(x,y)$ pairs.\n",
    "\n",
    "### Discrete Data Points\n",
    "Data is the result of an experiment, so we don't have a function, and we cannot even generate more data points. We must make do with what we are given. Example: from an experiment, you have velocity as a function of time, but want to calulate displacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Two Main Types of Numerical Integration: Numerical Solutions to Differential Equations\n",
    "Given some differential equations (equation involving a function and its derivatives), solve for various *functions*. For instance,\n",
    "\n",
    "$$ (2.2\\,\\mathrm{kg})\\frac{d^2x}{dt^2} + \\left(200\\,\\mathrm{\\frac{N}{m}}\\right)x(t) = 0$$\n",
    "\n",
    "This is the differential equation that relates the position of a harmonic oscillator with its acceleration. If we could \"integrate\" this equation from some initial conditions, say $x(0) = 5\\,{\\mathrm{m}}$ and $v(0) = x^\\prime(0) = 0$, we could determine the position of the oscillator $x$ at any time $t$.\n",
    "\n",
    "We'll deal with these later; first up is more traditional \"integration\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Methods of Integration: Riemann Integration\n",
    "We've beaten Riemann Integration to death in this class, but as a reminder, this is when we divide the domain into many pieces, and then sum up the areas of rectangles formed by these regions. The widths of the rectangles are the distances between adjacent $x$ values, the the heights are taken as the value of the function evaluated at one of the endpoints (or the midpoint).\n",
    "\n",
    "No cheater function in `numpy` or `scipy` to do this, but you already know how to create your own riemann integrator, which is much easier with `numpy` arrays.\n",
    "\n",
    "The next slide shows an example with way too few rectangles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# function we want approximate integrals for\n",
    "f = lambda x: np.exp(-x) * np.sin(x**2)\n",
    "f_string = '$f(x) = e^{-x}\\sin(x^2)$'\n",
    "\n",
    "# create 12 regions (13 points) over the domain (0 to 3 in this example)\n",
    "a = 0\n",
    "b = 3\n",
    "xs_bar, dx = np.linspace(a, b, 13, retstep=True)\n",
    "\n",
    "# get heights of rectangles using left edge, midpoint, and right end point for each rectangel\n",
    "ys_bar_left = f(xs_bar[:-1])\n",
    "ys_bar_mid = f((xs_bar[:-1] + xs_bar[1:]) / 2.0)\n",
    "ys_bar_right = f(xs_bar[1:])\n",
    "ys_bar = (ys_bar_left, ys_bar_mid, ys_bar_right)\n",
    "\n",
    "# sum up rectangle areas for each set of rectangles\n",
    "sums = [np.sum(dx * ys) for ys in ys_bar]\n",
    "\n",
    "# for creating labels in the subplots\n",
    "labels = ('Left Edge', 'Midpoint', 'Right Edge')\n",
    "\n",
    "# smooth data for the \"real\" function\n",
    "xs_smooth = np.linspace(0, 3, 100)\n",
    "ys_smooth = f(xs_smooth)\n",
    "\n",
    "# create a 3-panel figure to show the three methods\n",
    "fig, axes = plt.subplots(3, 1, sharex=True, figsize=(8, 5))\n",
    "\n",
    "# plot rectangles as blue bars, function as gold line, and show label, including sum, in the upper right\n",
    "for ax, ys, label, app_sum in zip(axes, ys_bar, labels, sums):\n",
    "    ax.bar(xs_bar[:-1], ys, width=dx, align='edge', edgecolor='black')\n",
    "    ax.plot(xs_smooth, ys_smooth, color='Goldenrod', lw=2)\n",
    "    ax.set_ylabel('$f(x)$')\n",
    "    ax.text(0.98, 0.96, '{}: {:.5f}\\n{}'.format(label, app_sum, f_string), ha='right', va='top', transform=ax.transAxes)\n",
    "axes[-1].set_xlabel('$x$')\n",
    "\n",
    "# tighten things up a bit, and then save to png\n",
    "plt.tight_layout()\n",
    "fig.savefig('riemann_panels.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The choice of Riemann sums only matters for small numbers of rectangles\n",
    "![riemann sum panels](riemann_panels.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Trapezoidal Integration is a great tool when dealing with discrete data\n",
    "Suppose you have a dataset rather than a function, and you need to integrate it. Then you are stuck with either right-handed or left-handed Riemann integration.\n",
    "\n",
    "There's another option, though, which is what we did in a previous homework set: the trapezoid rule. We use the two points on the $x$-axis as well as the left *and* right points along the function curve to define a trapezoid, which has an area of\n",
    "\n",
    "$$ A_{\\rm trap} = \\frac{1}{2} b (h_1 + h_2)$$\n",
    "\n",
    "Since the base $b$ is just the width of the rectangle, $\\Delta x$ and the heights are just the values of the functions $y_{\\rm left}$ and $y_{\\rm right}$. Thus, the factor of $\\frac{1}{2}(y_1+y_2)$ is just the average of the two heights, which is what we used in problem set 11 (arrays; Riemann Integration Revisited)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plotting trapezoids is harder... need to create each shape as a series of x,y pairs\n",
    "xy_points = []\n",
    "for xleft, xright, yleft, yright in zip(xs_bar[:-1], xs_bar[1:], f(xs_bar[:-1]), f(xs_bar[1:])):\n",
    "    ax.add_patch(patches.Polygon(xy=list(zip([xleft, xleft, xright, xright],[0, yleft, yright, 0])), ec='black'))\n",
    "ax.plot(xs_smooth, ys_smooth, color='goldenrod', lw=3)\n",
    "ax.text(0.98, 0.95, 'Trapezoidal: {:.5f}\\n{}'.format(np.trapz(f(xs_bar), xs_bar), f_string), ha='right', va='top', transform=ax.transAxes)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig('trapezoidal.png', dpi=150, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# `numpy` has you covered: `trapz`\n",
    "\n",
    "<img width=\"50%\" alt=\"Area under a function broken down into trapezoids\" src=\"trapezoidal.png\" style='float: left;'>\n",
    "<p>\n",
    "    Give it $y$ and then $x$ values, and <code>np.trapz</code> will do the sum of the trapezoidal areas: \n",
    "<p>\n",
    "<code>area = np.trapz(ys, xs)</code>\n",
    "</p>\n",
    "<p>\n",
    "Plotting this is a bit harder, though (see previous cell if you're curious).\n",
    "    </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Better, but More Complicated: Simpson's Rule\n",
    "<div>\n",
    "    <img alt=\"shaded areas of approximated polynomials of a function\" src=\"simpson.png\" style='float:left; width:50%'> \n",
    "    <p> <strong>The idea</strong>: Take pairs of intervals (so regions defined by <b>3</b> points), and approximate the function passing through each three points as a parabola. Then do a bunch of simple quadratic definite integrals. See a simple example in the next cell.\n",
    "    </p>\n",
    "    <p>\n",
    "      Cheater function is in <code>scipy</code>'s <code>integrate</code> submodule <code>scipy.integrate.simps(ys, xs)</code>\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(xs_smooth, ys_smooth, color='goldenrod', lw=3)\n",
    "\n",
    "# keep track of area as we go along\n",
    "area = 0\n",
    "\n",
    "# loop over the pairs of regions (so every other point is now a \"left\" point;\n",
    "# must have an odd number of points/even number of REGIONS to make this work)\n",
    "for i in range(0, len(xs_bar) - 2, 2):\n",
    "    # grab three consecutive points and their corresponding y-values\n",
    "    xs = xs_bar[i:i+3]\n",
    "    ys = f(xs)\n",
    "    \n",
    "    # ask numpy for a degree 2 polynomial fit; gives coefficients in\n",
    "    # descending order of degree (quadratic, linear, constant)\n",
    "    coeffs = np.polyfit(xs, ys, 2)\n",
    "    \n",
    "    # do some jank calculus to get the area under the curve\n",
    "    a, b = xs[0], xs[-1]\n",
    "    # the anti-derivative as a function (reverse power rule)\n",
    "    # reversed the coefficients, so the index of each coefficient would\n",
    "    # coincide with the degree (0th term is the constant coefficient,\n",
    "    # 1st term is the linear, etc.)\n",
    "    P = lambda x: sum([coeff / (i + 1) * x**(i+1) for i, coeff in enumerate(reversed(coeffs))])\n",
    "    # the definite integral of this region\n",
    "    area += (P(b) - P(a))\n",
    "    \n",
    "    # create smooth points along the approximate polynomial, plot them as\n",
    "    # dotted line, and then fill between the x-axis and the polynomial\n",
    "    interval_xs = np.linspace(min(xs), max(xs))\n",
    "    interval_ys = coeffs[2] + coeffs[1] * interval_xs + coeffs[0] * interval_xs**2\n",
    "    ax.plot(interval_xs, interval_ys, ls=':', lw=2)\n",
    "    ax.fill_between(interval_xs, interval_ys, color='C0', ec='black', zorder=-5)\n",
    "\n",
    "ax.text(0.98, 0.95, 'Simpson: {:.5f}\\n{}'.format(area, f_string), ha='right', va='top', transform=ax.transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig('simpson.png', dpi=150, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The Most Complicated, but Best Option for a Smooth Function: Gaussian Quadrature\n",
    "\n",
    "**Carl Friedrich Gauss** realized a sort of \"best case Simpson's Rule\", where he could minimize the error by using some very special polynomials. Yep, it's the Legendre polynomials again. For a well-behaved function over the interval \\[-1,1\\], he found he could approximate the integral to shockingly high precision with very few ($n$) points via\n",
    "\n",
    "$$\\int_{-1}^1 f(x)\\,dx \\approx \\sum_{i=1}^n w_i f(x_i)$$\n",
    "\n",
    "where the **weights** $w_i$ are given by\n",
    "\n",
    "$$ w_i = \\frac{2}{(1 - x_i^2)[P_n^\\prime(x_i)]^2}$$\n",
    "\n",
    "and $x_i$ are the **roots** of the $n$<sup>th</sup> Legendre polynomial (where $P_n(x_i) = 0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Challenge: Gaussian Quadrature By Hand\n",
    "Compute the following integral using Gaussian quadrature with just two points, and then check the answer by doing it by hand.\n",
    "\n",
    "$$\\int_{-1}^1 (3x^3 + 2x^2 - 5)dx = \\sum_{i=1}^nw_i(3x_i^3 + 2x_i^2 - 5)$$\n",
    "\n",
    "Recall that\n",
    "$$ w_i = \\frac{2}{(1 - x_i^2)[P_n^\\prime(x_i)]^2},$$\n",
    "\n",
    "but typically we just look up these weights in a table since they are *independent of the function*. You really just need to look up the roots and their associated weights, and then compute the weighted sum of the values of the function at the roots of the $n$<sup>th</sup> Legendre function. You will find [wikipedia's table of roots of the Legendre polynomials and the corresponding weights](https://en.wikipedia.org/wiki/Gaussian_quadrature#Gauss–Legendre_quadrature) helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# What is this witchcraft?!\n",
    "It turns out that *n*-point Gaussian quadrature is ***exact*** for polynomials of order 2*n*–1 and below, which is kind of ridculous. To get an exact integral of a 11<sup>th</sup> degree polynomial, you only need to know 5 values of the polynomial.\n",
    "\n",
    "Still, integrating polynomials is not that hard to do by hand with antiderivatives. The real value for Gaussian quadrature is that it requires so few points to get shockingly accurate results, even for transcendental functions.\n",
    "\n",
    "Before we had computers to compute millions of rectangles, this was *essential*, because computing 10,000 points or more was not exactly feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# But... my interval is not –1 to +1.\n",
    "Don't worry! We can just rescale the integral to one that is:\n",
    "\n",
    "$$\\int_a^bf(x)\\,dx = \\frac{b-a}{2}\\int_{-1}^1f\\left(\\frac{b-a}{2}\\xi + \\frac{a+b}{2}\\right)d\\xi$$\n",
    "\n",
    "Here we've just done a substitution where\n",
    "$$x = \\frac{b-a}{2}\\xi + \\frac{a+b}{2} \\qquad dx = \\frac{b-a}{2}d\\xi$$\n",
    "\n",
    "You can see that when $x=a$, $\\xi=-1$, and when $x=b$, $\\xi=1$. The main price we have to pay is that our function now has this scaling and shifting, and the overall result is modulated by $(b-a)/2$, but other than that, it's Gaussian quadrature to the rescue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Gaussian Quadrature in `scipy`\n",
    "This is a powerful tool, but `scipy.integrate`'s `quad` function makes it extremely trivial to use.\n",
    "\n",
    "You give `scipy.integrate.quad` a function as its first argument, a left endpoint, a right endpoint, and then any additional arguments the function needs (if the function takes multiple arguments, that is; if it's a function of one variable, you can just skip that). Notably, you don't need to fool around with the number of points, the weights, the roots, etc.\n",
    "\n",
    "## Return values\n",
    "`quad` yields back two values:\n",
    "- The approximate definite integral\n",
    "- An upper bound on the error in the definite integral\n",
    "\n",
    "So be careful when \"catching\" results, since `quad` will always hand back two!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example: Gaussian Quadrature with Our Old Function\n",
    "Use `quad` to compute the definite integral of\n",
    "$$f(x) = e^{-x}\\sin(x^2)$$\n",
    "over from $x=0$ to $x=3$, and report the uncertainty in the result. Don't forget to import the `quad` function from the appropriate submodule!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the integral using quad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# `dblquad`, `tplquad`, and `nquad` Compute Higher Dimensional Integrals\n",
    "Suppose we want to compute the integral\n",
    "$$\\int_{0}^1\\int_0^{1 - x}\\int_{0}^{1 - x - y}(5x - 3y)\\,dz\\,dy\\,dx$$\n",
    "Now the limits of the various integrals are not in general constant values, but they are functions of the other integration variables.\n",
    "\n",
    "The calling sequences of `dblquad` and `tplquad` are similar to `quad`, with more arguments for the limits. However, the **limits after the first two must be functions, even if they are constants**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import tplquad\n",
    "res, err = tplquad(lambda x, y, z: 5 * x - 3 * y, 0, 1, lambda x: 0, lambda x: 1 - x, lambda x, y: 0, lambda x, y: 1 - x - y)\n",
    "res, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ordinary Differential Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Setup: What are Ordinary Differential Equations?\n",
    "**Ordinary differential equations (ODEs)**: are equations that involve one or more unknown functions, their variables, and their derivatives.\n",
    "\n",
    "A **First Order ODE** is an ODE with the highest derivative being the first derivative of the function.\n",
    "\n",
    "$$\\frac{dx}{dt} = -x^3 + \\sin(t)$$\n",
    "\n",
    "A **Second Order ODE** is an ODE with the highest derivative being the seecond derivative of the function. These are extremely common in physics and engineering.\n",
    "$$m\\frac{d^2x}{dt^2} = -kx$$\n",
    "\n",
    "There are many tricks to solving these \"by hand\" **analytically** (see MATH 312), but we want to find **numerical** solutions. That is, can I get an array of times and an array of values of the function to plot, even if I don't know the actual functional form?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The Euler Method: An Intuitive, But Bad, Approach\n",
    "Let's start with a first-order ODE:\n",
    "\n",
    "$$\\frac{dx}{dt} = -x^3 + \\sin(t) = f(t, x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We want to find what the function $x(t)$ looks like. Suppose also that we do know that $x(0) = 0$ (an **initial condition**). How might we find the value of $x$ at some time later... say $t=10$?\n",
    "\n",
    "To approach this problem, we will break the time domain into tiny steps, called **timesteps** (and we might use this terminology even if we aren't dealing with a function of time). So at timestep 0 ($t=0$), we have $x=0$ and $dx/dt = -(0)^3 + \\sin(0) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "To get from one timestep to the next, we assume the derivative is constant, or that the function is linear with a slope equal to the local derivative:\n",
    "\n",
    "$$x_{n+1} = x_n + \\left(\\frac{dx}{dt}\\right)_ndt = x_n + f(t_n, x_n)dt$$\n",
    "\n",
    "After enough timesteps, we have \"integrated\" to the time we want, and we'll have the values of $x(t)$ up to that point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example: Euler's Method (Solution at End)\n",
    "Goal: Use Euler's Method to compute and plot the values of $x(t)$ up to $t=10$ for the ODE\n",
    "\n",
    "$$\\frac{dx}{dt} = f(t,x) = -x^3 + \\sin(t);\\qquad x(0) = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "\n",
    "f = lambda t, x: -x**3 + np.sin(t)\n",
    "\n",
    "# initial condition\n",
    "xi = 0\n",
    "# TODO: Calculate values of x and t from t = 0 to t = 10, and then plot them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Next few cells are additional background and examples; not necessary, and we won't cover them in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## The Second-Order Runge-Kutta Method\n",
    "This looks like a nice solution, but it's actually a pretty poor way to solve an ODE. This is because the value of each step is due to the derivative at the _beginning_ of the timestep. In reality, some sort of average derivative over the whole time interval between timesteps would be ideal. In the limit of smaller and smaller timesteps, this wouldn't matter, but taking the \"average\" value to be the value at the beginning is about the worst thing we can do.\n",
    "\n",
    "Second-order Runge Kutta improves upon this by approximating the derivative at the middle of the timestep. However, we don't actually know that derivative (because knowing the derivative requires knowing the time, which is ok, and knowing the position, which is essentially the thing we are trying to get at!). To get around this, we will use the Euler method to approximate the value of the function halfway through the timestep, and then we will use _that_ to get the derivative in the middle of the timestep, getting a better estimate.\n",
    "\n",
    "$$k_1 = f(x_n, t_n)\\Delta t$$\n",
    "$$k_2 = f\\left(x + \\frac{1}{2}k_1, t + \\frac{1}{2}\\Delta t\\right)\\Delta t$$\n",
    "$$x_{n+1} = x_n + k_2$$\n",
    "\n",
    "Note the part (calculating $k_1$ is essentially using the Euler method to get the change in $x$ after one timestep. We then take half of that difference, add it to the current value of $x$, and use that to find the derivative of the function halfway through the timestep in calculating $k_2$. We then use the change in $x$ using this derivative ($k_2$) to add to the previous value of $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# use same timesteps, initial condtions, and function as Euler method calculation (don't change them)\n",
    "\n",
    "# set up array of solution values\n",
    "xs_rk2 = np.zeros_like(ts)\n",
    "xs_rk2[0] = xi\n",
    "\n",
    "# iterate through times, adding new position for each time\n",
    "# note, we skip the last time since each step through the loop\n",
    "# calculates the NEXT value of x\n",
    "for i in range(0, len(ts) - 1):\n",
    "    k_1 = f(ts[i], xs_rk2[i]) * dt\n",
    "    k_2 = f(ts[i] + dt/ 2.0, xs_rk2[i] + k_1 / 2.0) * dt\n",
    "    xs_rk2[i + 1] = xs_rk2[i] + k_2\n",
    "    \n",
    "# now we're done! plot the solution\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(ts, xs_euler, label='Euler')\n",
    "ax.plot(ts, xs_rk2, ls='--', label='RK2')\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$x(t)$')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Fourth-Order Runge-Kutta Method (RK4)\n",
    "The second-order Runge-Kutta solution is definitely more accurate than the Euler method solution by making the relatively simple change to the calculation of the derivative. We can actually do better. We could keep making tighter and tighter approximations to get the \"average\" derivative over a timestep. The cost is that we have more and more intermediate calcuations. The \"sweet spot\" for most application is the fourth-order Runge-Kutta method, or simply RK4, which works like this:\n",
    "\n",
    "$$k_1 = f(x_n, t_n)\\Delta t$$\n",
    "$$k_2 = f\\left(x+\\frac{1}{2}k_1, t+\\frac{1}{2}\\Delta t\\right)\\Delta t$$\n",
    "$$k_3 = f\\left(x+\\frac{1}{2}k_2, t+\\frac{1}{2}\\Delta t\\right)\\Delta t$$\n",
    "$$k_4 = f(x+k_3, t+\\Delta t)\\Delta t$$\n",
    "$$x_{n+1} = x_n + \\frac{1}{6}\\left(k_1 + 2k_2 + 2k_3 + k_4\\right)$$\n",
    "You can see, the final \"derivative\" used is a sort of weighted average of each of the approximations. We won't cover in detail how we got to this approximation, but it is quite powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# use same timesteps, initial condtions as Euler method calculation (don't change them)\n",
    "\n",
    "# set up array of solution values\n",
    "xs_rk4 = np.zeros_like(ts)\n",
    "xs_rk4[0] = xi\n",
    "\n",
    "# iterate through times, adding new position for each time\n",
    "# note, we skip the last time since each step through the loop\n",
    "# calculates the NEXT value of x\n",
    "for i in range(0, len(ts) - 1):\n",
    "    k_1 = f(ts[i], xs_rk4[i]) * dt\n",
    "    k_2 = f(ts[i] + dt / 2.0, xs_rk4[i] + k_1 / 2.0) * dt\n",
    "    k_3 = f(ts[i] + dt / 2.0, xs_rk4[i] + k_2 / 2.0) * dt\n",
    "    k_4 = f(ts[i] + dt, xs_rk4[i] + k_3) * dt\n",
    "    xs_rk4[i + 1] = xs_rk4[i] + (1.0 / 6.0) * (k_1 + 2 * k_2 + 2 * k_3 + k_4)\n",
    "    \n",
    "# now we're done! plot the solution\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(ts, xs_euler, label='Euler')\n",
    "ax.plot(ts, xs_rk2, ls='--', label='RK2')\n",
    "ax.plot(ts, xs_rk4, ls=':', label='RK4')\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$x(t)$')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The \"Cheater\" Method: Use `scipy.integrate`'s `solve_ivp` function\n",
    "IVP = Initial Value Problem. This is the type of ODE solution where we know some initial value, and we want to integrate out from there.\n",
    "\n",
    "## Parameters\n",
    "- `fun`: a function; the function on the right side of the ODE ($f(t, x)$ in our example. First argument should be the \"time\"-like variable, and second should be the value of the function ($x(t)$ in our example).\n",
    "- `t_span`: tuple of two floats, the beginning and ending values of time to be integrated over\n",
    "- `y0`: array of initial values (initial value for simple problems will just have one element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The \"Cheater\" Method: Use `scipy.integrate`'s `solve_ivp` function\n",
    "## Notable Optional Parameters\n",
    "- `method`: string indicating which method of integration (defaults to 5th order Runge-Kutta)\n",
    "- `t_eval`: array of time points over which to make sure we evaluate the function. Without this, you're at the mercy of `solve_ivp`'s algorithm, which will usually give out very few, but highly accurate points.\n",
    "- `dense_output`: boolean. If `True`, returns a function rather than discrete points\n",
    "- `vectorized`: boolean. If `True`, it assumes that `fun` is vectorized (useful for solving systems of equations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The \"Cheater\" Method: Use `scipy.integrate`'s `solve_ivp` function\n",
    "\n",
    "## Return value of `solve_ivp`\n",
    "It returns an **object**, not a tuple, so we need to know the attributes of this object. These are the most notable attributes.\n",
    "- `t`: array of time points (if you specify `t_eval`, this should be the same)\n",
    "- `y`: 2D array of function values corresponding to the times in `t`\n",
    "- `sol`: the function-like object returned if `dense_output` was set to `True`\n",
    "\n",
    "So to plot a result, you might do something like\n",
    "```python\n",
    "sol = solve_ivp(f, (t_start, t_stop), y0)\n",
    "plt.plot(sol.t, sol.y[0,:])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example: Using `solve_ivp` to get a solution\n",
    "Solve the same differential equation for $x(t)$ using `solve_ivp` over the interval $t=0$ to $t=10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: solve ODE for x(t) and plot it, along with other strategies from before\n",
    "# (execute the optional Runge-Kutta cells if you skipped them)\n",
    "from scipy.integrate import solve_ivp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ODES with more than one variable\n",
    "Suppose we have a *system* of ODES, involving multiple variables. We'll study the famous **Lorenz Equations**, which are part of a simplified model of weather (something to do with convection in the atmosphere):\n",
    "\n",
    "$$\\frac{dx}{dt}=\\sigma(y-x),\\qquad \\frac{dy}{dt} = rx - y - xz,\\qquad \\frac{dz}{dt} = xy - bz$$\n",
    "\n",
    "Where $\\sigma$, $r$, and $b$ are all parameters (constants). We'll use $\\sigma=10$, $r=28$ and $b=8/3$.\n",
    "\n",
    "Note here how the derivatives of all three variables ($x$, $y$ and $z$) depend on the values of the other variables. None are explicitly dependent on time, but that could also be the case.\n",
    "\n",
    "**The Goal:** Generate arrays of times, as well as values of $x$, $y$, and $z$, starting from some values for time (probably zero), $x_0$, $y_0$, and $z_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The Strategy: More of the Same, but Vectorized\n",
    "While still a bad choice, the Euler Method still works conceptually:\n",
    "\n",
    "$$x_{n+1} = x_n + f_x(t_n, x_n, y_n, z_n)dt$$\n",
    "$$y_{n+1} = y_n + f_y(t_n, x_n, y_n, z_n)dt$$\n",
    "$$z_{n+1} = z_n + f_z(t_n, x_n, y_n, z_n)dt$$\n",
    "\n",
    "where the $f_i$ functions are the derivatives of variable $i$. To clean this up, let's define a vector $\\mathbf{x}$ that encompasses all three variables, and a function $\\mathbf{f}(t, \\mathbf{x})$, that takes in the current state and returns a vector of derivatives.\n",
    "$$\\mathbf{x}_n = \\begin{pmatrix}x_n\\\\y_n\\\\z_n\\end{pmatrix}; \\qquad \\mathbf{f}(t, \\mathbf{x}) = \\begin{pmatrix}\\frac{dx}{dt}\\\\\\frac{dy}{dt}\\\\\\frac{dz}{dt}\\end{pmatrix}$$\n",
    "and so, the Euler step becomes\n",
    "$$\\mathbf{x}_{n+1} = \\mathbf{x}_n + \\mathbf{f}(t_n, \\mathbf{x}_n)dt$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Translating this to Scipy\n",
    "`solve_ivp` works *nearly identically* for a system of equations. Our initial state is simply an array of initial values, $f$ is now a function that takes in a time as well as a **vector** of values, and the return value's `y` attribute now makes more sense, as it will shape of $(n, m)$ where $n$ is the number of timesteps, and $m$ is the number of functions we are solving for.\n",
    "\n",
    "Here's the workflow:\n",
    "- Define a `numpy` array of starting values for the various functions\n",
    "- Define a function that takes in two arguments (time and an array of current values of the various functions) and returns a `numpy` array of values of the functions' derivatives\n",
    "- Set the `vectorized` keyword to `True` (this tells is that our function expects an array input and gives an array output), and call `solve_ivp` with the function as the first argument, some two-tuple of starting and ending times (like before), and the array of starting values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example: The Lorenz Equations\n",
    "Solve for $x(t)$, $y(t)$, and $z(t)$ for the Lorenz equations to a time of 50, and then make a plot of $z$ vs. $x$. Assume starting conditions of $x_i=0$, $y_i=1$, $z_i=0$, and $t_i = 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# fixed parameters\n",
    "sigma = 10\n",
    "r = 28\n",
    "b = 8.0/3.0\n",
    "\n",
    "# the lorenz equations; set up to take time and vector in order of x, y, z\n",
    "# so y - x becomes x_vec[1] - x_vec[0]\n",
    "f_x = lambda t, x_vec: sigma * (x_vec[1] - x_vec[0])\n",
    "f_y = lambda t, x_vec: r * x_vec[0] - x_vec[1] - x_vec[0] * x_vec[2]\n",
    "f_z = lambda t, x_vec: x_vec[0] * x_vec[1] - b * x_vec[2]\n",
    "\n",
    "# TODO: Make plot of z vs x after solving this system of equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Second-Order ODEs: Nothing More Than Two Coupled First-Order ODEs!\n",
    "Next we'll tackle the classic problem of the undamped, undriven harmonic oscillator:\n",
    "\n",
    "$$ F = ma = m\\frac{d^2x}{dt^2} = -kx$$\n",
    "\n",
    "We know how to deal with first-order ODEs now, but this is a second order ODE. Or is it? What if we instead consider the acceleration to be the **first derivative of the velocity**?\n",
    "\n",
    "$$ m\\frac{dv}{dt} = -kx$$\n",
    "\n",
    "Now it looks like a first-order ODE, but I've introduced a new variable, so I need a new equation. The solution is so simple it might not seem obvious..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The Answer: Use the Definition of Velocity\n",
    "The definiton of velocity is itself a first-order ODE involving position and velocity:\n",
    "$$ \\frac{dx}{dt} = v$$\n",
    "\n",
    "We simply use the definition of velocity to create a second first-order ODE. So now we have a system of two first-order ODEs in two variables, $x$ and $v$. Putting this in our vectorized notation, we get\n",
    "\n",
    "$$\\mathbf{f}(t, \\mathbf{x}) = \\begin{pmatrix}\\frac{dx}{dt}\\\\\\frac{dv}{dt}\\end{pmatrix} = \\begin{pmatrix}v\\\\-\\frac{k}{m}x\\end{pmatrix}$$\n",
    "\n",
    "So once we know the initial conditions for **both position and velocity**, we can solve this like any other system of first-order ODEs. As a bonus, we get the velocity as a function of time for free!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# The Takeaway\n",
    "When facing a second-order ODE, you can numerically solve it by converting it to a system of two first-order ODEs. Do this by writing the second derivative as the derivative of the first derivative (but call it a new variable, like $v$), and then use the definition of this new variable (set it equal to the first derivative of the original variable) as the second equation.\n",
    "\n",
    "For instance, \n",
    "$$\\frac{d^2x}{dt^2} = \\left(\\frac{dx}{dt}\\right)^2 + 3\\frac{t}{x(t)}$$\n",
    "\n",
    "Becomes the system\n",
    "$$\\frac{dv}{dt} = v(t)^2 + 3\\frac{t}{x(t)}$$\n",
    "$$\\frac{dx}{dt} = v(t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Example: The Harmonic Oscillator\n",
    "Plot the position vs time for a harmonic oscillator with spring constant $k=750\\,\\mathrm{N/m}$ and mass $m=1.5\\,\\mathrm{kg}$ within an initial displacement of 25 cm and an initial speed of 0 m/s. Plot this over a time window of 1 second, and also show the analytic solution over this range:\n",
    "$$x(t) = x_0\\cos\\left(\\sqrt{\\frac{k}{m}}t\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "k = 750    # N/m\n",
    "m = 1.5    # kg\n",
    "x0 = 0.25  # m\n",
    "v0 = 0.0   # m/s\n",
    "\n",
    "# TODO: Solve ODE for positions, then plot position vs time, and\n",
    "# compare to analytic (\"known\") solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Solutions (but try them first!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Gaussian Quadrature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "f = lambda x: np.exp(-x) * np.sin(x**2)\n",
    "sol, err = quad(f, 0, 3)\n",
    "print('The integral is {:.15f} ± {:.2e}'.format(sol, err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# 1D Euler Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# the right-hand side of the ODE\n",
    "f = lambda t, x: -x**3 + np.sin(t)\n",
    "# the initial value of x\n",
    "xi = 0\n",
    "\n",
    "# total number of points to use... could play with this\n",
    "# higher values = better results, but slower calculation\n",
    "n_points = 20\n",
    "\n",
    "# get time points, but hold on to separation in dt\n",
    "# (retstep = True does this)\n",
    "ts, dt = np.linspace(0, 10, n_points, retstep=True)\n",
    "\n",
    "# initialize empty array of function values to hold on\n",
    "# to solution; initialize zeroth element to initial condition\n",
    "xs_euler = np.zeros_like(ts)\n",
    "xs_euler[0] = xi\n",
    "\n",
    "# take series of Euler steps to populate array. Note: only need\n",
    "# times up next-to-last value since time n gets us position n+1.\n",
    "for i, t in enumerate(ts[:-1]):\n",
    "    xs_euler[i + 1] = xs_euler[i] + dt * f(t, xs_euler[i])\n",
    "\n",
    "# plot the results!\n",
    "plt.plot(ts, xs_euler)\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$x(t)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## 1D `solve_ivp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# set up context; note, ts, xs_euler, xs_rk2, and xs_rk4 were initialized\n",
    "# in earlier cells, so you might need those\n",
    "f = lambda t, x: -x**3 + np.sin(t)\n",
    "\n",
    "sol = solve_ivp(f, (0, 10), np.array([xi]), t_eval=ts)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ts, xs_euler, label='Euler')\n",
    "ax.plot(ts, xs_rk2, ls='--', label='RK2')\n",
    "ax.plot(ts, xs_rk4, ls=':', label='RK4')\n",
    "\n",
    "# get time values from solution object, \"y\" values just means the\n",
    "# function values. Note that we take the zeroth element, because\n",
    "# the solution object is always a 2D array (solve_ivp is built\n",
    "# from the ground up for systems of equations; this will make more\n",
    "# sense later)\n",
    "ax.plot(sol.t, sol.y[0], ls='-.', label='solve_ivp')\n",
    "\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$x(t)$')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Solutions: Systems of ODEs and 2nd-Order ODEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "# fixed parameters\n",
    "sigma = 10\n",
    "r = 28\n",
    "b = 8.0/3.0\n",
    "\n",
    "# the lorenz equations\n",
    "f_x = lambda t, x_vec: sigma * (x_vec[1] - x_vec[0])\n",
    "f_y = lambda t, x_vec: r * x_vec[0] - x_vec[1] - x_vec[0] * x_vec[2]\n",
    "f_z = lambda t, x_vec: x_vec[0] * x_vec[1] - b * x_vec[2]\n",
    "\n",
    "# starting conditions\n",
    "x_vec_0 = np.array([0, 1, 0])\n",
    "\n",
    "# vectorized derivative function\n",
    "f = lambda t, x_vec: np.array([f_x(t, x_vec), f_y(t, x_vec), f_z(t, x_vec)])\n",
    "\n",
    "t_points = np.linspace(0, 50, 10000)\n",
    "solution = solve_ivp(f, (min(t_points), max(t_points)), x_vec_0, t_eval=t_points, vectorized=True)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "gs = fig.add_gridspec(3, 3)\n",
    "\n",
    "ax = fig.add_subplot(gs[:, 1:])\n",
    "ax.plot(solution.y[0,:], solution.y[2, :])\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$z$')\n",
    "\n",
    "ax_z = fig.add_subplot(gs[2, 0])\n",
    "ax_y = fig.add_subplot(gs[1, 0], sharex=ax_z)\n",
    "ax_x = fig.add_subplot(gs[0, 0], sharex=ax_z)\n",
    "ax_x.plot(solution.t, solution.y[0,:])\n",
    "ax_x.set_ylabel('$x$')\n",
    "ax_y.plot(solution.t, solution.y[1,:])\n",
    "ax_y.set_ylabel('$y$')\n",
    "ax_z.plot(solution.t, solution.y[2,:])\n",
    "ax_z.set_ylabel('$z$')\n",
    "ax_z.set_xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "k = 750    # N/m\n",
    "m = 1.5    # kg\n",
    "x0 = 0.25  # m\n",
    "v0 = 0.0   # m/s\n",
    "\n",
    "ts = np.linspace(0, 1, 1000)\n",
    "analytic_xs = x0 * np.cos(np.sqrt(k / m) * ts)\n",
    "\n",
    "# f should give back array of [dx/dt, dv/dt], which is\n",
    "# [v, -k/m x]. Assume input vector is in order [x, v],\n",
    "# consistent with the order of the output derivatives,\n",
    "# so x = x_vec[0], v = x_vec[1]\n",
    "f = lambda t, x_vec: np.array([x_vec[1], -k / m * x_vec[0]])\n",
    "\n",
    "solution = solve_ivp(f, (min(ts), max(ts)), np.array([x0, v0]), t_eval=ts, vectorized=True)\n",
    "\n",
    "plt.plot(solution.t, solution.y[0,:], lw=2, label='solve_ivp')\n",
    "plt.plot(ts, analytic_xs, ls='--', lw=2, label='Analytic')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Time [seconds]')\n",
    "plt.ylabel('Displacement [m]')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "rise": {
   "theme": "solarized",
   "transition": "fade"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
